{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto I. Desarrollar un Modelo de Lenguaje desde Cero usando PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente proyecto invita a los interesados a embarcarse en la construcción de modelos de lenguaje desde cero, empleando técnicas accesibles para generar texto de manera creativa. Se utilizará un conjunto de datos de nombres para demostrar cómo distintos modelos pueden producir resultados realistas y atractivos. El proyecto inicia con modelos básicos de bigramas y trigramas para comprender sus capacidades y avanza hacia una Red Neuronal Recurrente (RNN) más sofisticada, ampliando así las posibilidades creativas.\n",
    "\n",
    "**Fase I. Construcción de un Modelo Básico de Bigrama**\n",
    "\n",
    "En esta fase, se desarrollará un modelo básico de bigramas para generar y optimizar nombres utilizando trigramas, permitiendo apreciar las ventajas de modelos de n-gramas más complejos.\n",
    "\n",
    "**Fase II. Implementación de Redes Neuronales**\n",
    "\n",
    "En esta fase, se implementarán redes neuronales para perfeccionar el modelo. Se diseñará una RNN personalizada que capture patrones profundos en los nombres. Después de entrenarla, se utilizará esta RNN para generar nombres que demuestren la potencia de las redes neuronales en la creación de textos naturales y coherentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase I. Fundamentos de la Modelización del Lenguaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Iniciar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En este innovador proyecto, los interesados diseñarán modelos de bigramas y trigramas, así como un avanzado modelo generador de nombres basado en redes neuronales. Se aprovecharán potentes bibliotecas de Python en cada etapa del desarrollo, desde el procesamiento de datos hasta la construcción y optimización meticulosa de la red neuronal.\n",
    "\n",
    "El repositorio de [GitHub](https://github.com/Jeshua-Romero-Guadarrama/LinkedIn-Jeshua-Romero-Guadarrama/tree/main/Data_Science_Projects/Proyecto_I) contiene los archivos esenciales para completar el proyecto:\n",
    "\n",
    "- [/Proyecto_I/nombres.txt](https://github.com/Jeshua-Romero-Guadarrama/LinkedIn-Jeshua-Romero-Guadarrama/blob/main/Data_Science_Projects/Proyecto_I/nombres.txt): Archivo que contiene los nombres que se utilizarán para entrenar el modelo.\n",
    "- [/Proyecto_I/proyecto.ipynb](https://github.com/Jeshua-Romero-Guadarrama/LinkedIn-Jeshua-Romero-Guadarrama/blob/main/Data_Science_Projects/Proyecto_I/proyecto.ipynb): Cuaderno de Python donde se implementará el modelo. Cada sección del proyecto está asociada a una o varias celdas en el cuaderno, identificadas por su encabezado correspondiente.\n",
    "\n",
    "Al finalizar este proyecto, los participantes adquirirán un profundo conocimiento sobre la creación de modelos de lenguaje basados en bigramas y trigramas para generar texto a partir de secuencias de caracteres. Además, serán capaces de construir una Red Neuronal Recurrente personalizada en PyTorch para generar nombres únicos y aprenderán a optimizar el rendimiento del modelo mediante técnicas avanzadas de optimización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Importar los Módulos Necesarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se configurará el entorno y familiarizará con el cuaderno de Jupyter proporcionado para construir el modelo de lenguaje desde cero. El cuaderno [/Proyecto_I/proyecto.ipynb](https://github.com/Jeshua-Romero-Guadarrama/LinkedIn-Jeshua-Romero-Guadarrama/blob/main/Data_Science_Projects/Proyecto_I/proyecto.ipynb) será el espacio de trabajo principal para implementar las secciones del proyecto.\n",
    "\n",
    "En principio, se importarán los módulos de Python necesarios, incluyendo ```torch```, ```torch.nn```, ```torch.optim```, ```matplotlib.pyplot``` y ```random```. Dichos módulos se utilizarán extensivamente a lo largo del proyecto para desarrollar y visualizar el modelo de lenguaje.\n",
    "\n",
    "- ```numpy```: Biblioteca utilizada para realizar cálculos matemáticos y manipulaciones en arreglos, matrices, etc.\n",
    "- ```torch```: Biblioteca principal de PyTorch, utilizada para el cálculo de tensores y la construcción de redes neuronales.\n",
    "- ```torch.nn```: Submódulo de PyTorch que proporciona clases y funciones para construir capas y arquitecturas de redes neuronales.\n",
    "- ```torch.optim```: Submódulo de PyTorch utilizado para la optimización de algoritmos.\n",
    "- ```matplotlib.pyplot```: Biblioteca de gráficos utilizada para crear visualizaciones estáticas, interactivas y animadas en Python.\n",
    "- ```random```: Módulo que proporciona funciones para generar números aleatorios y realizar operaciones aleatorias.\n",
    "\n",
    "Ejecute el siguiente código en el archivo [/Proyecto_I/proyecto.ipynb](https://github.com/Jeshua-Romero-Guadarrama/LinkedIn-Jeshua-Romero-Guadarrama/blob/main/Data_Science_Projects/Proyecto_I/proyecto.ipynb) para importar los módulos necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importar módulos necesarios\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota:** Utilizar ```Shift + Enter``` para ejecutar una sola celda en el cuaderno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Cargar y Preprocesar los Datos de Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se cargará un conjunto de datos de nombres desde un archivo de texto y se preprocesará convirtiéndolos a minúsculas y añadiendo marcadores de inicio y fin. Luego, se calculará la frecuencia de bigramas (secuencias de dos caracteres consecutivos) en el conjunto de datos.\n",
    "\n",
    "Realice las siguientes operaciones en esta sección:\n",
    "\n",
    "1. Abra el archivo [/Proyecto_I/nombres.txt](https://github.com/Jeshua-Romero-Guadarrama/LinkedIn-Jeshua-Romero-Guadarrama/blob/main/Data_Science_Projects/Proyecto_I/nombres.txt) que contiene el conjunto de datos de nombres y divida su contenido en una lista de nombres individuales.\n",
    "2. Itere a través de cada nombre en el conjunto de datos y preprocéselo convirtiéndolo a minúsculas y añadiendo marcadores de inicio y fin (```<```, ```>```).\n",
    "\n",
    "Ejecute el siguiente código para cargar los datos desde el archivo de texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "with open('nombres.txt', 'r') as archivo:\n",
    "    nombres = archivo.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el siguiente código para preprocesar los nombres convirtiéndolos a minúsculas y añadiendo marcadores de inicio y fin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocesamiento de nombres\n",
    "nombres = ['<' + nombre.lower() + '>' for nombre in nombres]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota:** El conjunto de datos para este proyecto es una lista de nombres ubicada en [/Proyecto_I/nombres.txt](https://github.com/Jeshua-Romero-Guadarrama/LinkedIn-Jeshua-Romero-Guadarrama/blob/main/Data_Science_Projects/Proyecto_I/nombres.txt) y obtenida de un sitio web sobre [Seguridad Social](https://www.ssa.gov/oact/babynames/limits.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Construir y Visualizar la Tabla de Bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se creará una tabla de búsqueda para analizar la ocurrencia de bigramas dentro del conjunto de datos de nombres. Se construirá la tabla de búsqueda y se visualizará la frecuencia de ocurrencia de bigramas.\n",
    "\n",
    "Se realizarán las siguientes operaciones en esta sección:\n",
    "\n",
    "1. Inicializar la ```tabla_busqueda``` para contar las ocurrencias de bigramas. Será de tamaño 28 por 28 e incluirá 26 letras del alfabeto inglés y 2 caracteres especiales.\n",
    "2. Después de inicializar la tabla de búsqueda, cree un codificador ```char_a_int``` para mapear caracteres del alfabeto a enteros.\n",
    "3. Itere a través del conjunto de nombres para contar las ocurrencias de cada bigrama y almacene estos conteos en la tabla de búsqueda.\n",
    "4. Grafique la tabla de búsqueda para visualizar la frecuencia de ocurrencia de bigramas utilizando un diagrama de dispersión.\n",
    "\n",
    "Utilizar el siguiente código para inicializar y ordenar el vocabulario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inicializar y ordenar el vocabulario\n",
    "vocabulario    = set(''.join(nombres))\n",
    "vocabulario    = ''.join(sorted(vocabulario))\n",
    "tabla_busqueda = torch.zeros((len(vocabulario), len(vocabulario)), dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  **Nota**: En lugar de codificar los valores manualmente, intentar computar el vocabulario (alfabeto en este caso) a partir del texto, para que funcione en cualquier otro idioma con un alfabeto diferente.\n",
    "\n",
    "Utilizar el siguiente código para crear un codificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un codificador\n",
    "char_a_int = {char: i for i, char in enumerate(vocabulario)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar el cálculo de las transiciones de bigramas utilizando el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular las transiciones de bigramas\n",
    "for nombre in nombres:\n",
    "    for i in range(len(nombre) - 1):\n",
    "        ix1 = char_a_int[nombre[i]]\n",
    "        ix2 = char_a_int[nombre[i + 1]]\n",
    "        tabla_busqueda[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar los conteos de bigramas utilizando el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar x, y y conteos para el diagrama de dispersión\n",
    "x       = [i for i in range(len(tabla_busqueda)) for _ in range(len(tabla_busqueda[0]))]\n",
    "y       = [j for _ in range(len(tabla_busqueda)) for j in range(len(tabla_busqueda[0]))]\n",
    "conteos = [tabla_busqueda[i][j] for i in range(len(tabla_busqueda)) for j in range(len(tabla_busqueda[0]))]\n",
    "\n",
    "# Visualizar los conteos de bigramas\n",
    "plt.figure(figsize = (10, 8))\n",
    "dispersion = plt.scatter(x, y, s = conteos, c = conteos, cmap = 'Reds', alpha = 0.7)\n",
    "plt.xticks(ticks = np.arange(len(vocabulario)), labels = vocabulario)\n",
    "plt.yticks(ticks = np.arange(len(vocabulario)), labels = vocabulario)\n",
    "plt.xlabel('Primer Carácter')\n",
    "plt.ylabel('Segundo Carácter')\n",
    "plt.title('Conteos de Bigrama')\n",
    "plt.colorbar(dispersion, label = 'Conteo')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  **Nota**: En este gráfico, las burbujas más grandes en la parte inferior izquierda del gráfico, correspondientes a la primera mitad del alfabeto, indican que estos pares de caracteres ocurren con mayor frecuencia en el conjunto de datos. Esto sugiere que los bigramas con letras del inicio del alfabeto son más comunes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Generar Nombres con el Modelo de Bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se creará una función ```generar_nombre()``` para generar nombres utilizando un modelo de lenguaje de bigramas. Esta función empleará un enfoque probabilístico para seleccionar cada carácter en el nombre generado basado en la distribución de probabilidad del carácter precedente desde una tabla de búsqueda. El proceso continuará hasta que se alcance un carácter final.\n",
    "\n",
    "Siga estos pasos para completar la función:\n",
    "\n",
    "1. Inicialice cada nombre con un carácter de inicio ```<``` y una ```cadena_inicio``` opcional. Seleccione cada carácter subsiguiente basado en las probabilidades de bigramas, continuando hasta alcanzar el carácter de fin ```>```.\n",
    "2. Asegure que los nombres generados sean únicos y tengan al menos tres caracteres.\n",
    "3. Genere e imprima al menos 10 nombres únicos utilizando la función ```generar_nombre()``` (para imprimir un nombre significativo, incluya nombres con al menos tres caracteres de longitud).\n",
    "\n",
    "Ejecute el siguiente código para completar esta sección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar nombres con el Modelo de Lenguaje de Bigrama\n",
    "def generar_nombre(cadena_inicio = ''):\n",
    "    nombre = '<' + cadena_inicio.lower()\n",
    "    while True:\n",
    "        ix1 = char_a_int[nombre[-1]]\n",
    "        probabilidades_siguiente = tabla_busqueda[ix1]\n",
    "        peso_total = sum(probabilidades_siguiente)\n",
    "        if peso_total > 0:\n",
    "            siguiente_caracter = random.choices(vocabulario, weights = probabilidades_siguiente, k = 1)[0]\n",
    "        else:\n",
    "            siguiente_caracter = random.choice(vocabulario)\n",
    "        if siguiente_caracter == '>':\n",
    "            break\n",
    "        nombre += siguiente_caracter\n",
    "    return nombre[1:].capitalize()\n",
    "\n",
    "# Generar e imprimir 10 nombres únicos usando el Modelo de Lenguaje de Bigrama\n",
    "nombres_unicos = set()\n",
    "while len(nombres_unicos) < 10:\n",
    "    nombre = generar_nombre('Joe')    \n",
    "    if '<' + nombre.lower() + '>' not in nombres:\n",
    "        nombres_unicos.add(nombre)\n",
    "\n",
    "for nombre in nombres_unicos:\n",
    "    print(nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  **Nota**: Intente reemplazar ```random.choices(vocabulario, weights=probabilidades_siguiente, k=1)[0]``` con ```random.choices(vocabulario, k=1)[0]``` en el código. Compare los nombres generados antes y después de este cambio para apreciar el efecto de diferentes esquemas de ponderación en el modelo de lenguaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Generar Nombres Utilizando Trigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se extenderá el modelo de lenguaje previamente construido para generar nombres utilizando trigramas. El objetivo es mejorar la comprensión de los patrones de nombres por parte del modelo al considerar secuencias de tres caracteres en lugar de dos.\n",
    "\n",
    "Para lograr esta sección, realice los siguientes pasos:\n",
    "\n",
    "1. Crear una tabla de búsqueda, ```tabla_busqueda_trigrama```, ajustando la tabla de búsqueda anterior para acomodar trigramas mediante la introducción de una tercera dimensión para almacenar los conteos de transiciones de trigramas.\n",
    "2. Actualizar la función de generación de nombres a una nueva función ```generar_nombre_trigrama()``` que seleccione el siguiente carácter probabilísticamente basado en los dos caracteres precedentes (trigrama), asegurando que los nombres generados exhiban patrones más realistas.\n",
    "3. Generar e imprimir al menos 10 nombres únicos con la función ```generar_nombre_trigrama()```, utilizando este modelo de trigramas para patrones más realistas.\n",
    "\n",
    "Actualice la tabla de búsqueda para trigramas utilizando el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar las dimensiones de la tabla de búsqueda para trigramas\n",
    "tabla_busqueda_trigrama = torch.zeros((len(vocabulario), len(vocabulario), len(vocabulario)), dtype = torch.int32)\n",
    "\n",
    "# Calcular las transiciones de trigramas\n",
    "for nombre in nombres:\n",
    "    for i in range(len(nombre) - 2):\n",
    "        ix1 = char_a_int[nombre[i]]  \n",
    "        ix2 = char_a_int[nombre[i + 1]]\n",
    "        ix3 = char_a_int[nombre[i + 2]]\n",
    "        tabla_busqueda_trigrama[ix1, ix2, ix3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el siguiente código para generar nombres utilizando el Modelo de Lenguaje de Trigrama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función del Modelo de Trigrama\n",
    "def generar_nombre_trigrama(cadena_inicio = ''):\n",
    "    nombre = '<' + cadena_inicio\n",
    "    while True:\n",
    "        if len(nombre) < 2:\n",
    "            siguiente_caracter = random.choice(vocabulario)\n",
    "        else:\n",
    "            ix1 = char_a_int[nombre[-2]]\n",
    "            ix2 = char_a_int[nombre[-1]]\n",
    "            probabilidades_siguiente = tabla_busqueda_trigrama[ix1, ix2]\n",
    "            peso_total = sum(probabilidades_siguiente)\n",
    "            if peso_total > 0:\n",
    "                siguiente_caracter = random.choices(vocabulario, weights = probabilidades_siguiente, k = 1)[0]\n",
    "            else:\n",
    "                siguiente_caracter = random.choice(vocabulario)\n",
    "        if siguiente_caracter == '>':\n",
    "            break\n",
    "        nombre += siguiente_caracter\n",
    "    return nombre[1:].capitalize()\n",
    "\n",
    "# Generar e imprimir 10 nombres únicos usando el Modelo de Lenguaje de Trigrama\n",
    "nombres_unicos = set()\n",
    "while len(nombres_unicos) < 10:\n",
    "    nombre = generar_nombre_trigrama('Joe')    \n",
    "    if '<' + nombre.lower() + '>' not in nombres:\n",
    "        nombres_unicos.add(nombre)\n",
    "\n",
    "for nombre in nombres_unicos:\n",
    "    print(nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase II. Mejorar los Modelos de Lenguaje con Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Definir un Decodificador y Convertir Caracteres a Tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se definirán los componentes esenciales para el procesamiento de datos requeridos antes de entrenar el modelo de Red Neuronal Recurrente (RNN).\n",
    "\n",
    "Defina lo siguiente para facilitar el procesamiento de datos:\n",
    "\n",
    "1. **Diccionario ```int_a_char```**: Este es un decodificador que mapea caracteres del alfabeto a enteros.\n",
    "2. **Función ```char_a_tensor(texto)```**: Esta función convierte una cadena de caracteres en una representación tensorial. Esta conversión es necesaria ya que las redes neuronales operan con datos numéricos, y los tensores son la estructura de datos fundamental para la manipulación de datos en PyTorch.\n",
    "\n",
    "Ejecute el siguiente código para completar esta sección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificador\n",
    "int_a_char = {idx: char for idx, char in enumerate(vocabulario)}\n",
    "\n",
    "# Convertir una cadena de caracteres a un tensor de índices enteros\n",
    "def char_a_tensor(texto):\n",
    "    return torch.tensor([char_a_int[char] for char in texto], dtype = torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Diseñar la Arquitectura de la RNN para la Modelización del Lenguaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se definirá un modelo de Red Neuronal Recurrente (RNN) personalizado utilizando PyTorch. Se implementará la clase ```RNNPersonalizada```, que hereda de ```nn.Module```. Dicha clase incluirá una capa de embedding, una capa GRU (Unidad Recurrente Gated) y una capa totalmente conectada (lineal) para la salida. Las **GRU** son un tipo de capa RNN diseñada para manejar datos secuenciales mientras abordan los problemas de los gradientes que desaparecen, lo que las hace efectivas para capturar dependencias en secuencias más largas mediante la actualización o el olvido selectivo de información.\n",
    "\n",
    "Completar las siguientes operaciones:\n",
    "\n",
    "1. En el método ```__init__```, defina una capa de embedding para convertir los índices de entrada en vectores densos, una capa GRU para manejar los datos de secuencia con la dimensión oculta especificada, y una capa totalmente conectada para mapear la salida de la GRU al tamaño de salida deseado. El método ```__init__``` toma los siguientes parámetros:\n",
    "- Tamaño de entrada (```input_size```): El tamaño del vocabulario, que define el número de tokens únicos que pueden ser embebidos.\n",
    "- Tamaño de embedding (```embed_size```): La dimensionalidad de la capa de embedding, que convierte cada token de entrada en una representación vectorial densa de este tamaño.\n",
    "- Dimensión oculta (```hidden_dim```): El número de características en el estado oculto de la GRU, lo que determina la capacidad de la RNN para capturar dependencias de secuencias.\n",
    "- Tamaño de la salida (```output_size```): El número de clases de salida o dimensiones objetivo utilizadas por la capa totalmente conectada para generar la salida final.\n",
    "2. Defina el método ```forward()``` que determina cómo se procesan los datos de entrada a través de estas capas para generar predicciones de salida. Específicamente, aplique la capa de embedding a la entrada ```x```, reestructúrela según sea necesario para su procesamiento por la capa GRU, pásela a través de la GRU y utilice la capa totalmente conectada para generar la salida.\n",
    "\n",
    "Ejecute el siguiente código para completar esta sección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Personalizada\n",
    "class RNNPersonalizada(nn.Module):\n",
    "    def __init__(self, tamaño_entrada, tamaño_embed, dim_oculta, tamaño_salida):\n",
    "        super(RNNPersonalizada, self).__init__()\n",
    "        self.embedding  = nn.Embedding(num_embeddings = tamaño_entrada, embedding_dim = tamaño_embed)\n",
    "        self.gru        = nn.GRU(input_size = tamaño_embed, hidden_size = dim_oculta)\n",
    "        self.fc         = nn.Linear(dim_oculta, tamaño_salida)\n",
    "        self.dim_oculta = dim_oculta\n",
    "\n",
    "    def forward(self, x, oculto):\n",
    "        x               = self.embedding(x).view(1, 1, -1)\n",
    "        salida, oculto  = self.gru(x, oculto)\n",
    "        salida          = self.fc(salida.view(1, -1))\n",
    "        return salida, oculto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  Escribir Funciones para Generar el Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se implementarán funciones para generar nombres utilizando un modelo RNN. La función comienza inicializando el estado oculto con contexto de la ```cadena_inicio``` proporcionada, preparando el modelo para generar texto que fluya naturalmente desde la secuencia inicial. Luego, genera secuencialmente caracteres pasando el último carácter y el estado oculto al modelo, actualizando el estado oculto en cada paso, hasta que se genera el token de fin ```>``` o se alcanza la ```longitud``` especificada.\n",
    "\n",
    "Complete las siguientes operaciones:\n",
    "\n",
    "1. Implementar la función ```generar_nombre_rnn()``` para generar nombres utilizando un modelo RNN previamente entrenado. Esta función tomará como entradas el ```modelo```, una ```cadena_inicio```, la ```longitud``` y la ```temperatura```, y generará texto de la siguiente manera:\n",
    "- Inicialice el nombre con la ```cadena_inicio```, precedida por un token de inicio ```<```, y conviértalo en un tensor utilizando la función ```char_a_tensor()``` definida anteriormente.\n",
    "- Crear un estado oculto inicial para la RNN usando ```torch.zeros``` con dimensiones que coincidan con el tamaño oculto del modelo.\n",
    "- Iterar a través de la ```cadena_inicio``` para inicializar el estado oculto pasando cada tensor de carácter al modelo y estado oculto.\n",
    "- Comenzar a generar caracteres uno a uno hasta la ```longitud``` especificada:\n",
    "    - Utilizar el modelo para predecir el siguiente carácter basado en el tensor de carácter actual y el estado oculto.\n",
    "    - Aplicar una escala de temperatura para controlar la aleatoriedad en la selección de caracteres, y seleccione el siguiente carácter probabilísticamente desde la distribución de salida.\n",
    "    - Añadir el carácter predicho al texto generado, deteniéndose si se alcanza el token de fin ```>```.\n",
    "- Devolver el nombre final generado como una cadena capitalizada sin el token de inicio.\n",
    "2. Definir una función ```generar_nombres_unicos()``` para generar e imprimir un conjunto de nombres únicos, utilizando ```generar_nombre_rnn()``` para crear cada uno. Esta función tomará como argumentos el ```modelo```, una ```cadena_inicio``` y ```n``` (número de nombres a generar), y procederá de la siguiente manera:\n",
    "- Inicialice un conjunto vacío para almacenar nombres únicos.\n",
    "- En un ciclo, llame a la función ```generar_nombre_rnn()``` para generar un nuevo nombre utilizando la ```cadena_inicio``` proporcionada y la longitud máxima ```MAX_LONGITUD_NOMBRE```.\n",
    "- Añada cada nombre generado al conjunto. El uso de la estructura de datos set asegura que los nombres añadidos no se dupliquen.\n",
    "- Continúe generando nombres hasta que se hayan recopilado ```n``` nombres únicos.\n",
    "- Imprima cada nombre único generado por el modelo.\n",
    "\n",
    "Ejecute el siguiente código para completar esta sección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LONGITUD_NOMBRE         = 32\n",
    "\n",
    "# Generar texto con el modelo\n",
    "def generar_nombre_rnn(modelo, cadena_inicio = '', longitud = MAX_LONGITUD_NOMBRE, temperatura = 0.8):\n",
    "    cadena_inicio           = '<' + cadena_inicio.lower()\n",
    "    tensor_entrada          = char_a_tensor(cadena_inicio)\n",
    "    oculto                  = torch.zeros(1, 1, modelo.dim_oculta)\n",
    "    \n",
    "    for i in range(len(cadena_inicio) - 1):\n",
    "        _, oculto           = modelo(tensor_entrada[i].unsqueeze(0), oculto)\n",
    "    texto_generado          = cadena_inicio[1:]\n",
    "    caracter_entrada        = tensor_entrada[-1].unsqueeze(0)\n",
    "    \n",
    "    for _ in range(longitud):\n",
    "        salida, oculto      = modelo(caracter_entrada.unsqueeze(0), oculto)\n",
    "        distribucion_salida = salida.data.view(-1).div(temperatura).exp()\n",
    "        indice_top          = torch.multinomial(distribucion_salida, 1)[0]\n",
    "        siguiente_caracter  = int_a_char[indice_top.item()]\n",
    "        if siguiente_caracter == '>':\n",
    "            break\n",
    "        texto_generado      += siguiente_caracter\n",
    "        caracter_entrada    = char_a_tensor(siguiente_caracter)\n",
    "    \n",
    "    return texto_generado.capitalize()\n",
    "\n",
    "# Generar e imprimir n nombres únicos usando el Modelo de Lenguaje RNN\n",
    "def generar_nombres_unicos(modelo, cadena_inicio, n):\n",
    "    nombres_unicos = set()\n",
    "    while len(nombres_unicos) < n:\n",
    "        nombre = generar_nombre_rnn(modelo, cadena_inicio, MAX_LONGITUD_NOMBRE)\n",
    "        if '<' + nombre.lower() + '>' not in nombres:\n",
    "            nombres_unicos.add(nombre)\n",
    "    \n",
    "    for nombre in nombres_unicos:\n",
    "        print(nombre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Entrenar el Modelo RNN Personalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, se entrenará un modelo RNN personalizado utilizando el conjunto de datos proporcionado para aprender los patrones y la estructura subyacente de los datos de texto. Realice las siguientes operaciones en esta sección:\n",
    "\n",
    "1. Defina los parámetros de entrenamiento para el tamaño del embedding, la dimensión oculta y el número total de épocas.\n",
    "2. Inicialice el modelo, el optimizador y la función de pérdida para configurar el entrenamiento.\n",
    "3. Implemente un bucle de entrenamiento para iterar sobre cada época:\n",
    "- Mezcle el conjunto de datos de nombres al inicio de cada época para asegurar un orden de entrenamiento variado.\n",
    "- Para cada nombre en el conjunto de datos:\n",
    "    - Convierta el nombre en tensores de entrada y objetivo utilizando ```char_a_tensor()```.\n",
    "    - Inicialice el estado oculto para cada nuevo nombre.\n",
    "    - Reinicie los gradientes acumulados en el optimizador.\n",
    "    - Para cada carácter en el tensor de entrada:\n",
    "        - Realice una pasada hacia adelante a través del modelo para obtener predicciones.\n",
    "        - Calcule y acumule la pérdida comparando las predicciones con los objetivos.\n",
    "    - Después de procesar todo el nombre, retropropague la pérdida acumulada y actualice los parámetros del modelo.\n",
    "4. Rastrear y almacenar la pérdida promedio para cada época, añadiéndola a una lista, e imprima el progreso al final de cada época.\n",
    "5. Utilice ```generar_nombres_unicos()``` después de cada época para generar nombres de muestra, permitiendo observar el progreso del modelo.\n",
    "6. Después de completar todas las épocas, grafique la pérdida registrada para visualizar el progreso del entrenamiento.\n",
    "\n",
    "Ejecute el siguiente código para completar esta sección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir los parámetros de entrenamiento\n",
    "TAMAÑO_EMBED = 32\n",
    "DIM_OCULTA   = 32\n",
    "EPOCAS       = 3\n",
    "\n",
    "# Configuración del entrenamiento\n",
    "modelo       = RNNPersonalizada(len(vocabulario), TAMAÑO_EMBED, DIM_OCULTA, MAX_LONGITUD_NOMBRE)\n",
    "optimizador  = optim.Adam(modelo.parameters(), lr=0.005)\n",
    "criterio     = nn.CrossEntropyLoss()\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "perdidas     = []\n",
    "\n",
    "for epoca in range(EPOCAS):\n",
    "    perdida_total = 0\n",
    "    random.shuffle(nombres)  # Mezclar el conjunto de datos para asegurar un orden diferente en cada época\n",
    "    \n",
    "    for nombre in nombres:\n",
    "        entradas  = char_a_tensor(nombre[:-1])\n",
    "        objetivos = char_a_tensor(nombre[1:])\n",
    "        oculto    = torch.zeros(1, 1, DIM_OCULTA)\n",
    "        optimizador.zero_grad()\n",
    "        perdida   = 0\n",
    "    \n",
    "        for i in range(len(entradas)):\n",
    "            salida, oculto = modelo(entradas[i].unsqueeze(0), oculto)\n",
    "            perdida        += criterio(salida, objetivos[i].unsqueeze(0))\n",
    "        \n",
    "        perdida.backward()\n",
    "        optimizador.step()\n",
    "        perdida_total += perdida.item() / len(entradas)\n",
    "    \n",
    "    perdidas.append(perdida_total / len(nombres))\n",
    "    print(f'Época {epoca+1}, Pérdida: {perdida_total:.4f}')\n",
    "    generar_nombres_unicos(modelo, 'Joe', 10)\n",
    "    print('=' * 50)\n",
    "\n",
    "# Graficar la curva de pérdida\n",
    "plt.plot(range(1, EPOCAS + 1), perdidas)\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Pérdida de Entrenamiento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  **Nota**: Compare los nombres generados con los nombres generados anteriormente con bigramas y trigramas. Además, observe cómo el modelo se desempeña con diferentes cadenas de inicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Felicidades por completar el proyecto! Se ha realizado un excelente trabajo. Aplicar habilidades mediante proyectos prácticos como este es una excelente manera de familiarizarse con nuevas técnicas y tecnologías.\n",
    "\n",
    "Para continuar experimentando con lo desarrollado, intente crear y optimizar otros modelos y validarlos en diversos conjuntos de datos de prueba."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
